<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Alex Gu</title>
  
  <meta name="author" content="Alex Gu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Alex Gu</name>
              </p>
              <p>
                I am a PhD student at MIT advised by the wonderful <a href="https://people.csail.mit.edu/asolar/">Armando Solar-Lezama</a>.
                My research interests are to improve the capabilities of AI systems on tasks like programming and mathematics. 
                I also did my bachelor's and Master's degrees at MIT, advised by Armando and <a href="https://www.mit.edu/~jda/">Jacob Andreas</a>. I have done internships at Meta FAIR, Amazon ARG, NVIDIA, <a href="https://www.janestreet.com/">Jane Street</a>, and <a href="https://pony.ai/">pony.ai</a>. My research is generously funded by the NSF GRFP. 
                <br>
                <br>
                Outside research, I love music. I studied piano for over 15 years under inspiring pianists Yukiko Sekino and Chun-Chi An and
                received a music minor in my undergraduate. As a highlight, I performed the first movement of 
                <a href="https://www.youtube.com/watch?v=lIb2DgnhtsQ">Rachmaninoff's 2nd Piano Concerto</a> with the MIT Symphony Orchestra.
                I occasionally perform <a href="https://www.youtube.com/@minimario1729">piano recitals</a> and rarely make <a href="https://soundcloud.com/alex-gu-254660687">EDM-like tracks and remixes.</a>
                <br>
                <br>
                Email: gua [at] mit.edu
              </p>
              <p style="text-align:center">
                <!-- <a href="mailto:gua@mit.edu">Email</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?hl=en&user=jRQtBp0AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/minimario1729">Twitter</a> &nbsp/&nbsp
                <!-- <a href="https://sigmoid.social/@minimario">Mastodon</a> &nbsp/&nbsp -->
                <a href="https://soundcloud.com/alex-gu-254660687">SoundCloud</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/@minimario1729">YouTube</a> &nbsp/&nbsp
                <a href="images/wechat.jpg">WeChat</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/headshot.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/headshot.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-top:0px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p><b>[Jun 2025]</b> Our <a href="papers/challenges_ai4se.pdf">paper</a> on challenges and future directions in AI for Software Engineering is accepted to ICML 2025!</p>
              <p><b>[Apr 2025]</b> Zhaoyu Li and I are hosting a social on <a href="https://iclr.cc/virtual/2025/social/37595">AI for Mathematics and Theorem Proving</a> at ICLR 2025!</p>
              <!-- <p><b>[Apr 2025]</b> We have a <a href="papers/challenges_ai4se.pdf">new paper</a> on challenges and future directions in AI for Software Engineering!</p> -->
              <p><b>[Mar 2025]</b> I started an internship at Meta in Menlo Park working on AI and Lean with Aram Markosyan.</p> 
              <!-- <p><b>[Feb 2025]</b> LiveCodeBench, Mixture of Parrots, and BigCodeBench are accepted to ICLR 2025! See you in Singapore! </p> -->
              <!-- <p><b>[May 2024]</b> <a href="https://counterfeit-code.github.io/">The Counterfeit Conundrum</a> was accepted to ACL Findings, 2024. Look forward to enjoying Bangkok with everyone!</p> -->
              <!-- <p><b>[May 2024]</b> <a href="https://crux-eval.github.io/">CRUXEval</a> was accepted to ICML 2024! Try out our benchmark to see if your code models can reason about code execution, and see you in Vienna!</p> -->
              <!-- <p><b>[May 2024]</b> I will be doing an internship at NVIDIA with the LLM model optimization team led by Di Wu in Santa Clara! Let me know if you are in the Bay Area!</p>  -->
              <!-- <p><b>[Mar 2024]</b> <a href="https://arxiv.org/abs/2310.16803">Language Agnostic Code Embeddings</a> was accepted to NAACL 2024! Excited to catch up with friends in Mexico City!</p> -->
              <!-- <p><b>[Mar 2024]</b> Check out <a href="https://livecodebench.github.io/">LiveCodeBench</a>, our new holistic and contamination-free code benchmark!</p> -->
              <!-- <p><b>[Feb 2024]</b> Our new work, <a href="https://counterfeit-code.github.io/">the counterfeit conundrum</a>, questions the ability of code language models to understand their own incorrect generations.</p> -->
              <!-- <p><b>[Feb 2024]</b> Released <a href="https://huggingface.co/blog/starcoder2">StarCoder2</a>, a new family of code LMs achieving SoTA on many code generation tasks for models of the same size.</p> -->
              <!-- <p><b>[Jan 2024]</b> Check out our new benchmark, <a href="https://crux-eval.github.io/">CRUXEval</a>, designed to test the ability of code LMs to perform code execution reasoning!</p> -->
              <!-- <p><b>[Dec 2023]</b> <a href="https://arxiv.org/abs/2310.15164">LINC</a>, a neurosymbolic approach to logical reasoning, received an <b>outstanding paper award</b> at EMNLP 2023!</p> -->
              <!-- <p><b>[Oct 2023]</b> Released <a href="https://arxiv.org/abs/2310.16803">Language Agnostic Code Embeddings</a>, an approach to separate syntax and semantics for code embeddings!</p> -->
              <!-- <p><b>[Oct 2023]</b> I gave a <a href="https://www.youtube.com/watch?v=u-pkmdkQoMU">talk</a> about <a href="https://leandojo.org">LeanDojo</a> at Harvard! -->
              <!-- In addition, LeanDojo was selected for an oral presentation at NeurIPS 2023!</p> -->
              <!-- <p><b>[June 2023]</b> We released <a href="https://leandojo.org">LeanDojo</a>, an open-source playground to play with 
              LM's for theorem proving in Lean.</p> -->
              <!-- <p><b>[May 2023]</b> A recording of my <a href="https://www.youtube.com/watch?v=OnaIw3qgQdU">piano recital</a> this spring is now on YouTube (and below on this page)!</p> -->
              <!-- <p><b>[May 2023]</b> I'm interning at Meta AI Research under <a href="https://www.sidaw.xyz/">Sida Wang</a> this summer! If you're in the 
              Seattle area, I'd love to chat!</p> -->
              <!-- <p><b>[May 2023]</b> My <a href="https://www.youtube.com/watch?v=OSUl6ExR5M8">TEDxBoston talk on AI for Code is now online!</a></p> -->
              <!-- <p><b>[May 2023]</b> I was accepted to the <a href="https://music.ecu.edu/summer/piano-festival/yap/">ECPF</a> piano program and will 
              attend from June 24 - July 2, 2023!</p> -->
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-top:0px;width:100%;vertical-align:middle">
              <heading>Research Interests</heading>
              <p>My research dreams currently lie in these three (somewhat different) areas, though I'm currently focusing on the first two. 
              I'm very open to both collaborating and advising students (through UROP if you're an undergrad at MIT, 
              we can discuss otherwise), so don't hesitate to reach out if you're excited about these topics and would like to work together! </p> 
              <p>
                1. <a href="http://www.neurosymbolic.org/">Neurosymbolic programming</a>, specifically through the lens of 
                smashing symbolic techniques together with LLM's to create more reliable and powerful ways to perform program synthesis.
                <br>
                <br>
                2. Developing methodologies to interpret the behavior and understand the capabilities of code LM's,
                understand their reasoning abilities, and distinguish them from language LM's.
                <br>
                <br>
                3. Understanding theoretical foundations and training dynamics behind large language models (for code), 
                such as sensitivity to of initialization/learning rates, sharpness-aware training, or pruning.
              </p>
            </td>
          </tr>
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-top:0px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/ineqmath.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2506.07927">
              <papertitle>
                IneqMath: Solving Inequality Proofs with Large Language Models
              </papertitle>
            </a>
            <br>
            Jiayi Sheng*, Luna Lyu*, Jikai Jin, Tony Xia, <strong>Alex Gu</strong>, James Zou*, Pan Lu*
            <p></p>
            <p>
              In IneqMath, we dive deep into the ability of LLMs to solve Olympiad-level inequality proofs. We reveal a critical gap: LLMs are often good at finding answers, but struggle with rigorous, sound proofs.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/ai4swe.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://minimario.github.io/papers/challenges_ai4se.pdf">
              <papertitle>
                Challenges and Paths Towards AI for Software Engineering
              </papertitle>
            </a>
            <br>
            <em>ICML, 2025</em>
            <br>
            <strong>Alex Gu</strong>, Naman Jain, Wen-Ding Li, Manish Shetty, Yijia Shao, Ziyang Li, Diyi Yang, Kevin Ellis, Koushik Sen, Armando Solar-Lezama 
            <p></p>
            <p>
              In this paper, we first discuss challenges in today's AI systems for software engineering. Then,
              we propose a set of promising future research directions to address these challenges.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/moe.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2410.19034">
              <papertitle>
                Mixture of Parrots: Experts improve memorization more than reasoning
              </papertitle>
            </a>
            <br>
            Samy Jelassi, Clara Mohri, David Brandfonbrener, <strong>Alex Gu</strong>, Nikhil Vyas, Nikhil Anand, David Alvarez-Melis, Yuanzhi Li, Sham M. Kakade, Eran Malach
            <br>
            <em>ICLR, 2025</em>
            <p></p>
            <p>
              In this paper, we compare MoEs and dense transformers. Our main finding is that as the number of experts increases 
              at constant active parameter count, memorization performance increases while reasoning capabilities saturate.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/lcb.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://livecodebench.github.io/pdfs/paper.pdf">
              <papertitle>
                LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code
              </papertitle>
            </a>
            <br>
            Naman Jain, King Han, <strong>Alex Gu*</strong>, Wen-Ding Li*, Fanjia Yan*, Tianjun Zhang*, Sida Wang, Armando Solar-Lezama, Koushik Sen, Ion Stoica
            <br>
            <em>ICLR, 2025</em>
            <p></p>
            <p>
              <a href="https://livecodebench.github.io">LiveCodeBench</a> is a holistic and contamination-free
              benchmark for code LMs. It consists of 4 tasks: code generation, self-repair, code execution, 
              and test output prediction. We update the benchmark periodically with new high-quality problems 
              from platforms like LeetCode, AtCoder, and Codeforces.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/counterfeit.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://counterfeit-code.github.io/paper/counterfeit-conundrum.pdf">
              <papertitle>
                üïµÔ∏è The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?
              </papertitle>
            </a>
            <br>
            <strong>Alex Gu</strong>, Wen-Ding Li*, Naman Jain*, Theo X. Olausson*, Celine Lee*, Koushik Sen, Armando Solar-Lezama 
            <br>
            <em>ACL Findings, 2024</em>
            <p></p>
            <p>
              In <a href="https://counterfeit-code.github.io">The Counterfeit Conundrum</a>, we analyze the ability of
              open code language models to understand their <i>counterfeit samples</i>. These are samples that 
              1) have a high enough log-probability to be generated at a moderate temperature, 2) are incorrect, 
              but 3) pass weak correctness checks. We find that open code LMs 1) think counterfeits are correct,
              2) execute them as if they were correct, and 3) can't repair them without feedback.
            </p>
          </td>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/bigcode.jpg' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2402.19173">
              <papertitle>
                StarCoder2 and The Stack v2: The Next Generation
              </papertitle>
            </a>
            <br>
            Anton Lozhkov, ..., <strong>Alex Gu</strong>, ..., Leandro von Werra*, Harm de Vries*
            <br>
            <p></p>
            <p>
              We train new models with 3B, 7B, and 15B on Software Heritage source code including 619 programming 
              languages and high-quality data sources like GitHub pull requests, Kaggle notebooks, and code documentation. 
              Our models outperform most similarly sized models on a variety of benchmarks.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/cruxeval.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://crux-eval.github.io/paper/cruxeval.pdf">
              <papertitle>
                CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution
              </papertitle>
            </a>
            <br>
            <strong>Alex Gu</strong>, Baptiste Rozi√®re, Hugh Leather, Armando Solar-Lezama, Gabriel Synnaeve, Sida I. Wang
            <br>
            <em>ICML, 2024; DMLR & DPFM Workshops @ ICLR 2024</em>
            <p></p>
            <p>
              <a href="https://crux-eval.github.io/">CRUXEval</a> is a benchmark of 800 Python functions 
              and input-output pairs designed to test the ability of code LMs on code reasoning, understanding, 
              and execution. We find that despite being trained on 100G of Python code and 1T of code data, 
              models like Code Llama fail over half the time at simple execution prediction and code reasoning!
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/lace.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2310.16803">
              <papertitle>
                Language Agnostic Code Embeddings
              </papertitle>
            </a>
            <br>
            Saiteja Utpala, <strong>Alex Gu</strong>, Pin Yu Chen
            <br>
	    <em>NAACL, 2024</em>
            <p></p>
            <p>
              We apply a method used in multilingual NLP on code, showing that vector embeddings for code can be decomposed into 
              syntax-like and semantic-like components. We show that when removing the syntax-like component, language identification
              becomes expectedly difficult, and Text2Code and Code2Code retrieval performance improves.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/linc.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2310.15164">
              <papertitle>
                LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers
              </papertitle>
            </a>
            <br>
            <strong>Alex Gu*</strong>, Theo X. Olausson*, Benjamin Lipkin*, Cedegao E. Zhang*, Armando Solar-Lezama, Joshua B. Tenenbaum, Roger Levy
            <br>
            <em>EMNLP 2023, <b>Outstanding Paper Award in Commonsense and Reasoning</b></em>
            <br>
            <p></p>
            <p>
            We propose, LINC, a neurosymbolic approach to logical reasoning from natural language where the LLM acts as an 
            autoformalizer to first-order logic and a logic theorem prover makes a deduction. We also qualitatively compare LINC to chain of thought,
            showing they make different mistakes and thus are complimentary.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/leandojo_logo.jpg' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://leandojo.org/">
              <papertitle>
                LeanDojo: Theorem Proving with Retrieval-Augmented Language Models
              </papertitle>
            </a>
            <br>
            Kaiyu Yang, Aidan Swope, <strong>Alex Gu</strong>, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan Prenger, Anima Anandkumar
            <br>
	          <em>NeurIPS Datasets and Benchmarks Track 2023, <b>Oral presentation</b></em>
            <br>
            <p></p>
            <p>
              We release <a href="https://leandojo.org">LeanDojo</a>: an open-source playground consisting of toolkits, benchmarks,
              and models for LLMs to prove formal theorems in the Lean proof assistant. LeanDojo contains 1) tools for data extraction 
              and interaction with Lean, 2) fine-grained annotations of where lemmas are used and defined, 3) a new benchmark of 97K
              human-written theorems from mathlib, and 4) a retrieval-augmented theorem prover using retrieval for relevant premise selection.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/bigcode.jpg' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2305.06161">
              <papertitle>
                üí´ StarCoder: may the source be with you!
              </papertitle>
            </a>
            <br>
            Raymond Li, ..., <strong>Alex Gu</strong>, ..., Leandro von Werra*, Harm de Vries*
            <br>
            <em>TMLR, 2023</em>
            <p></p>
            <p>
              StarCoder and StarCoderBase are 15.5B parameter models with 8K context length, infilling capabilities,
              and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion
              tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with 
              inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, 
              resulting in the creation of StarCoder.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/codebert_pruning.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>
              Pruning CodeBERT for Improved Code-to-Text Efficiency [Coming Soon!]
            </papertitle>
            </a>
            <br>
            <strong>Alex Gu</strong>, Ria Sonecha, Saaketh Vedantam, Bharat Runwal, Diganta Misra
            <br>
            <em>Workshop on Sparsity in Neural Networks, ICLR 2023</em>
            <p></p>
            <p>
              We do some very preliminary experiments on pruning the encoder piece of CodeBERT. Preprint coming soon, 
              but if you're interested in this topic, please reach out!
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two">
              <img src='images/morbit.png' width="160">
              </div>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2203.01924">
              <papertitle>
                Min-Max Bilevel Multi-objective Optimization with Applications in Robust Machine Learning
              </papertitle>
            </a>
            <br>
            <strong>Alex Gu</strong>, Songtao Lu, Parikshit Ram, Lily Weng
            <br>
            <em>ICLR 2023 <a href="https://www.youtube.com/watch?v=ODP1nkG4kRc">[Video from ICML 2021 workshop]</a></em>
            <p></p>
            <p>
              We extend standard single-objective bilevel optimization to a min-max multi-objective framework that aims to minimize
              the worst-case loss of all tasks. Our main result is theoretical: we introduce a new algorithm (MORBiT) for our framework
              and show a convergence result. We also highlight applications in representation learning and hyperparameter optimization.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/bigcode.jpg' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/pdf/2301.03988.pdf">
              <papertitle>üéÖSantaCoder: Don't Reach for the Stars!üåü</papertitle>
            </a>
            <br>
            Loubna Ben Allal*, Raymond Li*, Denis Kocetkov*, ..., <strong>Alex Gu</strong>, ..., Leandro von Werra*
            <br>
            <em> Deep Learning for Code Workshop, ICLR 2023 [Best Paper] </em>
            <p></p>
            <p>
              The BigCode project is an open-scientific collaboration working on the responsible open-source development of large language models 
              for code. We train 1.1B parameter models on the Java, JavaScript, and Python subsets of The Stack, and our best model outperforms 
              previous open-source multilingual code generation models (InCoder-6.7B and CodeGen-Multi-2.7B) in both left-to-right generation and infilling.
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/obsynth.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2210.11468">
              <papertitle>ObSynth: An Interactive Synthesis System for Generating Object Models from Natural Language Specifications</papertitle>
            </a>
            <br>
            <strong>Alex Gu</strong>, Tamara Mitrovska, Daniela Velez, Jacob Andreas, Armando Solar-Lezama
            <br>
            <em> Deep Learning for Code Workshop, ICLR 2023 </em>
            <p></p>
            <p>
              ObSynth leverages domain knowledge embedded in GPT-3 to help users design object models from high level natural language prompts. 
              We synthesize object names, field names, field types, method names, and relationships between objects.
              Also, we conduct a user study to highlight how users may interact with ObSynth to design a restaurant management application.
            </p>
          </td>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/disagreement.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2202.01602">
              <papertitle>
                The Disagreement Problem in Explainable Machine Learning: A Practitioner's Perspective
              </papertitle>
            </a>
            <br>
            Satyapriya Krishna*, Tessa Han*, <strong>Alex Gu</strong>, Javin Pombra, Shahin Jabbari, Steven Wu, Himabindu Lakkaraju
            <br>
            <em>Workshop on Trust and Reliance in AI-Human Teams, CHI 2022</em>
            <p></p>
            <p>
              We introduce the disagreement problem in explainable machine learning, showing that commonly used
              algorithms including LIME, SHAP, and SmoothGrad often disagree in practice. We also conduct a user study
              highlighting that practitioners do not have good ways of resolving these disagreements in their day to day.
            </p>
          </td>
        </tbody></table>
				
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/tos.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2110.03274">
              <papertitle>
                Three Operator Splitting with Subgradients, Stochastic Gradients, and Adaptive Learning Rates
              </papertitle>
            </a>
            <br>
            Alp Yurtsever*, <strong>Alex Gu</strong>*, Suvrit Sra
            <br>
            <em>NeurIPS 2021 
              <a href="https://papertalk.org/papertalks/36220">[Video]</a>
            </em>
            <p>
              Standard three operator splitting minimizes the sum of three convex functions f(x) + g(x) + h(x), where f is smooth and the prox operators of
              g and h are computable. We focus on three settings: (i) f is nonsmooth, (ii) we only have noisy gradients and subgradients of f, (iii) an adaptive setting where smoothness properties of f are unknown.
            </p>
            <p>
              
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/corgi.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://ml4ad.github.io/files/papers2020/Certified%20Interpretability%20Robustness%20for%20Class%20Activation%20Mapping.pdf">
              <papertitle>
                Certified Interpretability Robustness for Class Activation Mapping
              </papertitle>
            </a>
            <br>
            <strong>Alex Gu</strong>, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, Luca Daniel
            <br>
            <em>Workshop on Machine Learning for Autonomous Driving, NeurIPS 2020 
              <a href="https://slideslive.com/38941515/certified-interpretability-robustness-for-class-activation-mapping">[Video]</a></em>
            <p></p>
            <p>
              Our algorithm, CORGI, computes certified bounds on an interpretability algorithm known as CAM (Class Activation Mapping), showing that within the certified radius,
              the top-K pixels of the CAM map do not change.
            </p>
          </td>
        </tbody></table>

       
        <heading style="padding-left:20px"> Invited Talks </heading>
        <p style="padding-left:20px"> If you find my work interesting, I am happy to give a talks to anyone who is interested! </p>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <ul>
            <li> June 2025: <i>AI for Software Engineering at <a href="https://www.usaaio.org">USA AI Olympiad</a> Training Camp (virtual)</li>
            <li> April 2025: <i>AI for Software Engineering: Where are we now, and what lies ahead?</i> at ICLR DL4C Workshop(Singapore) </li>
            <li> November 2024: <i>Beyond Code Generation: Reasoning about Code and Reasoning with Code</i> at ML Foundations Reading Group (Tsinghua, virtual) </li>
            <li> October 2024: <i>LeanDojo: Theorem Proving with Retrieval-Augmented Language Models</i> at Mathematics and Machine Learning Program (Harvard, virtual) </li>
            <li> March 2024: <i>Beyond Code Generation: Do code language models understand programs the same way humans do?</i> at Lei Lab (CMU, virtual), Cornell Tech, and Columbia PL/SE seminar </li>
            <li> February 2024: <i>CRUXEval: Code Reasoning, Understanding, and Execution Evaluation</i> at AGI Leap Summit (virtual) </li>
            <li> October 2023: <i>LeanDojo: Theorem Proving with Retrieval-Augmented Language Models</i> at CMSA New Technologies in Mathematics seminar (Harvard) </li>
            <li> May 2023: <i>What we need before even attempting to replace programmers with AI</i> at TEDxBoston </li>
          </ul>
        </tbody></table>

        <heading style="padding-left:20px"> Teaching Experience </heading>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <ul>
            <li> Spring 2022: TA, Nonlinear Optimization (MIT 6.252) </li>
            <li> Fall 2021: TA, Machine Learning (MIT 6.867) </li>
            <li> Spring 2020: TA, Signals, Systems, and Inference (MIT 6.011) </li>
          </ul>
        </tbody></table>

        <heading style="padding-left:20px"> Service </heading>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <ul>
            <li> AI for Math workshop and social organization <a href="https://mathai2024.github.io">[NeurIPS '24 Workshop (Lead)]</a>, <a href="https://iclr.cc/virtual/2025/social/37595">[ICLR '25 Social]</a>, <a href="https://sites.google.com/view/ai4mathworkshopicml2025/home">[ICML '25 Workshop]</a></li>
            <li> <a href="https://ioai-official.org/about/scientific-committee/">International Olympiad in Artificial Intelligence (IOAI)</a> scientific committee member </li>
            <li> Organizer of the <a href="http://www.neurosymbolic.org/reading-group.html">neurosymbolic programming reading group</a> at MIT.
            <li> Reviewer for AISTATS (2022, 2023), NeurIPS (2022, 2023, 2024), EMNLP (2022), ICML (2022, 2023), ICLR DL4C Workshop (2022, 2023), ICLR (2024) </li>
            <li> Artifact Evaluation Committee member, PLDI 2022 </li>
	    <li> Co-organizer of the <a href="https://mlcollective.org/icml-2021-open-collab-social/">ICML 2021 Social on Open Collaboration in ML Research</a> </li>
            <li> Outstanding reviewer for ML reproducibility challenge (2021) </li>
            <li> Student volunteer at POPL (2021), PLDI (2021), ICFP (2021) </li>
          </ul>
        </tbody></table>

        <heading style="padding-left:20px"> Olympiad Awards </heading>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <ul>
            <li> William Lowell Putnam Competition, Rank 185.5 / 4623 (2018), Rank 212 / 3428 (2019) </li>
            <li> 2016 USACO (USA Computing Olympiad) Finalist, National Top 26 </li>
            <li> 2015-2017 USAJMO / 2018 USAMO Qualifier </li>
            <li> 2017 USAPhO (USA Physics Olympiad) Honorable Mention Winner </li>
            <li> 2015 MATHCOUNTS National Team Champion, 3rd Place Individual </li>
          </ul>
        </tbody></tab e>

        <heading style="padding-left:20px"> Other Projects </heading>
    	<p style="padding-left:20px"> Here are some other projects I've worked on. If you're interested in building off any of them, I highly welcome collaborations! </p>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
          <td style="padding:20px;width:95%;vertical-align:middle;padding-bottom:0px;padding-top:5px">
            <strong>
		<a href="https://www.dropbox.com/s/hfzs4om0fip3uj7/RestBot_Project_Report%20%281%29.pdf?dl=0">
		RestBot - Online Interactive Breaks Revive Positive Thinking and Behavior during COVID-19
		</a> 
	    </strong>
            <br>
	    <p> The intention of this research project is to explore alternative methodologies available to people who are struggling with quarantine and isolation, providing them with an opportunity to resuscitate positive thinking and behavior. The result of the study proved that direct online social engagement can be an alternative way to resuscitate positive thinking and behavior for everyone under strenuous circumstances, such as during COVID. </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:95%;vertical-align:middle;padding-bottom:0px;padding-top:5px">
            <strong>
		<a href="https://www.dropbox.com/s/vr0gby4ero81t3p/Estimating%20the%20Lipschitz%20Constant%20of%20Neural%20Networks.pdf?dl=0">
		Estimating the Lipschitz Constant of Neural Networks
		</a>
	    </strong>
            <br>
	    <p> An (unsuccessful) attempt to estimate the Lipschitz constant of neural networks via running optimization techniques on the gradient norm. </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:95%;vertical-align:middle;padding-bottom:0px;padding-top:5px">
            <strong>
		<a href="https://github.com/minimario/dex-synthesis">
		Dex Synthesizer
		</a>
	    </strong>
            <br>
	    <p> A synthesizer for toy programs in the <a href="https://github.com/google-research/dex-lang">Dex Programming Language</a> 
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:95%;vertical-align:middle;padding-bottom:0px;padding-top:5px">
            <strong>
		<a href="https://github.com/minimario/founded-semantics">
		Exploring Founded Semantics for Static Analysis
		</a>
	    </strong>
            <br>
  	    <p> A toy exploration of how <a href="https://arxiv.org/pdf/1606.06269.pdf">founded semantics</a> can help static analysis. </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:95%;vertical-align:middle;padding-bottom:0px;padding-top:5px">
            <strong>
		<a href="https://github.com/gloriafang123/ml_fpga">
		Neural Network on FPGA
		</a>
	    </strong>
            <br>
	    <p> Implementation of a feedforward neural network on FPGA in Verilog </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:95%;vertical-align:middle;padding-bottom:0px;padding-top:5px">
            <strong>
		<a href="https://zhang-lucy.github.io/cuthbert-site/index.html">
		CUTHBERT: Comprehensive aUTo-arrangement algoritHm for BEats n‚Äô RhyThms
		</a>
	    </strong>
            <br>
	    <p> CUTHBERT, a music generator that uses Markov chain models to gain an intuition for music, is a software tool designed to remove knowledge barriers for new musicians and provide inspiration to experienced musicians that just need an idea to start writing. </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:95%;vertical-align:middle;padding-bottom:0px;padding-top:5px">
            <strong>
		<a href="https://www.dropbox.com/s/7azllp9ixu397k3/Comparing%20Sketching%20Algorithms%20for%20Nearest%20Neighbor%20Search.pdf?dl=0">
		Comparing Sketching Algorithms for Nearest Neighbor Search
		</a>
	    </strong>
            <br>
	    <p> A comparison of six different sketching algorithms for nearest neighbor search (run time/accuracy) on MNIST, GloVe, and SIFT. </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:95%;vertical-align:middle;padding-bottom:0px;padding-top:5px">
            <strong>
		<a href="https://github.com/minimario/ray-tracer">
		Ray Tracer
		</a>
	    </strong>
            <br>
	    <p>A ray-tracer written in OCaml based on <i>The Ray Tracer Challenge</i> by Jamis Buck.</p>
          </td>
        </tbody></table>

     
        <!-- Music stuff  -->
        <heading style="padding-left:20px"> Music </heading>
        <p style="padding-left:20px"> Previously, I studied classical piano under <a href="http://yukikosekino.com/index.html">Yukiko Sekino</a> and Chun-Chi An. Here are some recordings of concerts I have given in the past:</p>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <iframe width="300" height="200" src="https://www.youtube.com/embed/OnaIw3qgQdU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <strong>Recital, Spring 2023 <em><a href="https://www.dropbox.com/s/nevw8mxcz692g8m/2022%20Program.pdf?dl=0">[Program Notes]</a></em> </strong>
            <br>
            <p>
              Ludwig van Beethoven, Sonata Op. 57, No. 23 "Appassionata" (1806)
              <br>
              <br>
              Sergei Rachmaninoff, Sonata Op. 36, No. 2 (1913 - 1931)
              <br>
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <iframe id="chinese-music-video" width="300" height="200" src="https://www.youtube.com/embed/cRT0WJ3Gqes" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </td>
          <script>
            var videos = [
              'https://www.youtube.com/embed/cRT0WJ3Gqes',
              'https://www.youtube.com/embed/NYMANp3cpyk',
              'https://www.youtube.com/embed/E6l3dMOTvG8'
            ];

            var randomVideo = videos[Math.floor(Math.random() * videos.length)];
            console.log(randomVideo);
            document.getElementById('chinese-music-video').src = randomVideo;
          </script>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <strong>Chinese Music Concert, Spring 2023, <em><a href="https://www.dropbox.com/s/2skwx2c80pgdhzp/Chinese_Music_Concert.pdf?dl=0">[Program Notes]</a></em> </strong>
            <br>
            <p>
              <a href="https://www.youtube.com/watch?v=cRT0WJ3Gqes">ÁéãÂª∫‰∏≠, ÊµèÈò≥Ê≤≥ / Jianzhong Wang, Liuyang River (1972)</a>
              <br>
              <br>
              <a href="https://www.youtube.com/watch?v=NYMANp3cpyk">ÈªéËã±Êµ∑, Â§ïÈò≥ÁÆ´Èºì / Yinghai Li, Flute and Drum at Sunset (1975)</a>
              <br>
              <br>
              <a href="https://www.youtube.com/watch?v=E6l3dMOTvG8">ÈôàÈí¢, Èò≥ÂÖâÁÖßËÄÄÁùÄÂ°î‰ªÄÂ∫ìÂ∞îÂπ≤ / Gang Chen, Sunshine Over Tashkuergan</a>
              <br>
            </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <iframe width="300" height="200" src="https://www.youtube.com/embed/lVzLtsb5fk4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <strong>Recital, Spring 2022 <em><a href="https://www.dropbox.com/s/nevw8mxcz692g8m/2022%20Program.pdf?dl=0">[Program Notes]</a></em> </strong>
            <br>
            <p>
              Alexander Scriabin, Piano Sonata No. 2 in G-sharp minor (1897)
              <br>
              <br>
              John Adams, China Gates (1977)
              <br>
              <br>
              Philip Glass, Opening, from Glassworks (1995)
              <br>
              <br>
              Robert Schumann, Piano Sonata No. 2 in G minor (1838)
              <br>
            </p>
          </td>
        </tbody></table>
      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <iframe width="300" height="200" src="https://www.youtube.com/embed/lIb2DgnhtsQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <strong>Performance with MIT Symphony Orchestra, Spring 2022</strong>
            <br>
            <p>
              Rachmaninoff Piano Concerto No. 2 in C minor, Op. 18
              <br>
              I. Moderato
            </p>
          </td>
        </tbody></table>
      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <iframe width="300" height="200" src="https://www.youtube.com/embed/tm8NTuLqkZw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <strong>Recital, Spring 2021 <em><a href="https://www.dropbox.com/s/umsnu1k57zndd3y/2021%20Program.pdf?dl=0">[Program Notes]</a></em></strong>
            <br>
            <p>
              Claude Debussy, Images, Book 1 (1905)
              <br>
              <br>
              Fr√©d√©ric Chopin, Sonata No. 2 in B flat minor (1839)
              <br>
              <br>
              Sergei Rachmaninoff, Piano Concerto No. 2 in C minor, I. Moderato (1901)
            </p>
          </td>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <iframe width="300" height="200" src="https://www.youtube.com/embed/miQD0g_h9rY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <strong>Chamber Music, Spring 2021</strong>
            <br>
            <p>
              Edvard Grieg, Sonata No. 3 in C minor for Violin and Piano, Op. 45 (1887)
              <br>
              I. Allegro molto ed appassionato
              <br>
              II. Allegretto espressivo alla Romanza
            </p>
          </td>
        </tbody></table> -->

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <iframe width="300" height="200" src="https://www.youtube.com/embed/9bl2Jo7eM6g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <strong>Chamber Music, Spring 2021</strong>
            <br>
            <p>
              Francis Poulenc, Flute and Piano Sonata (1957)
              <br>
              I. Allegretto malincolico
            </p>
          </td>
        </tbody></table> -->

        <p style="padding-left:20px"> Once in a while, I also enjoy creating my own music. </p>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:50%;vertical-align:middle">
            <iframe width="100%" height="100%" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/736543189&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true&visual=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/alex-gu-254660687" title="Alex Gu" target="_blank" style="color: #cccccc; text-decoration: none;">Alex Gu</a> ¬∑ <a href="https://soundcloud.com/alex-gu-254660687/remembrance" title="Remembrance, ft. boomza654" target="_blank" style="color: #cccccc; text-decoration: none;">Remembrance, ft. boomza654</a></div>
          </td>
          <td style="padding:20px;width:50%;vertical-align:middle">
            <p> A sentimental piece that I co-created with my friend <a href="https://www.linkedin.com/in/krittamate-tiankanon-4892b4195/">Boom</a> once for New Year's. </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:50%;vertical-align:middle">
            <iframe width="100%" height="100%" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/550814835&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true&visual=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/alex-gu-254660687" title="Alex Gu" target="_blank" style="color: #cccccc; text-decoration: none;">Alex Gu</a> ¬∑ <a href="https://soundcloud.com/alex-gu-254660687/its-raining-tacos-edm-remix" title="It's Raining Tacos (EDM Remix)" target="_blank" style="color: #cccccc; text-decoration: none;">It's Raining Tacos (EDM Remix)</a></div>
          </td>
          <td style="padding:20px;width:50%;vertical-align:middle">
              <p> A remix of Parry Gripp's hit song, It's Raining Tacos, which often kept me sane in my undergraduate days. </p>
          </td>
        </tbody></table>
      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:50%;vertical-align:middle">
            <iframe width="100%" height="100%" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/731260690&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true&visual=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/alex-gu-254660687" title="Alex Gu" target="_blank" style="color: #cccccc; text-decoration: none;">Alex Gu</a> ¬∑ <a href="https://soundcloud.com/alex-gu-254660687/learn-to-meow" title="Learn to Meow (Â≠¶Áå´Âè´) Remix" target="_blank" style="color: #cccccc; text-decoration: none;">Learn to Meow (Â≠¶Áå´Âè´) Remix</a></div>
          </td>
          <td style="padding:20px;width:50%;vertical-align:middle">
            <p> A remix of another one of my guilty pleasure songs, Â≠¶Áå´Âè´ (Learn to Meow). </p>
          </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:50%;vertical-align:middle">
            <iframe width="100%" height="100%" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/373546406&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true&visual=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/alex-gu-254660687" title="Alex Gu" target="_blank" style="color: #cccccc; text-decoration: none;">Alex Gu</a> ¬∑ <a href="https://soundcloud.com/alex-gu-254660687/starships" title="Starships" target="_blank" style="color: #cccccc; text-decoration: none;">Starships</a></div>
          </td>
          <td style="padding:20px;width:50%;vertical-align:middle">
            <p> A surreal, jolly, but nostalgic piece reflecting on the past. </p>
          </td>
        </tbody></table>

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table> -->
        <!-- Make itemized bullet pointed list of reviewing duties -->
        <!-- make heading with 20 left padding -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the awesome website template. Last updated on June 20, 2025. 
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>
</html>
